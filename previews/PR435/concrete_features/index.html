<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Concrete Features · AbstractGPs.jl</title><meta name="title" content="Concrete Features · AbstractGPs.jl"/><meta property="og:title" content="Concrete Features · AbstractGPs.jl"/><meta property="twitter:title" content="Concrete Features · AbstractGPs.jl"/><meta name="description" content="Documentation for AbstractGPs.jl."/><meta property="og:description" content="Documentation for AbstractGPs.jl."/><meta property="twitter:description" content="Documentation for AbstractGPs.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AbstractGPs.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../api/">The Main APIs</a></li><li class="is-active"><a class="tocitem" href>Concrete Features</a><ul class="internal"><li><a class="tocitem" href="#Finite-dimensional-projection"><span>Finite dimensional projection</span></a></li><li><a class="tocitem" href="#Sample-from-GP-from-the-prior-at-x-under-noise."><span>Sample from GP from the prior at <code>x</code> under noise.</span></a></li><li><a class="tocitem" href="#Compute-the-log-marginal-probability-of-y."><span>Compute the log marginal probability of <code>y</code>.</span></a></li><li><a class="tocitem" href="#Construct-the-posterior-process-implied-by-conditioning-f-at-x-on-y."><span>Construct the posterior process implied by conditioning <code>f</code> at <code>x</code> on <code>y</code>.</span></a></li><li><a class="tocitem" href="#A-posterior-process-follows-the-AbstractGP-interface,-so-the-same-functions-which-work-on-the-posterior-as-on-the-prior."><span>A posterior process follows the <code>AbstractGP</code> interface, so the same functions which work on the posterior as on the prior.</span></a></li><li><a class="tocitem" href="#Compute-the-VFE-approximation-to-the-log-marginal-probability-of-y."><span>Compute the VFE approximation to the log marginal probability of <code>y</code>.</span></a></li><li><a class="tocitem" href="#Sequential-Conditioning"><span>Sequential Conditioning</span></a></li><li><a class="tocitem" href="#Plotting"><span>Plotting</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/0-intro-1d/">Intro to AbstractGPs: one-dimensional regression</a></li><li><a class="tocitem" href="../examples/1-mauna-loa/">Mauna Loa time series example</a></li><li><a class="tocitem" href="../examples/2-deep-kernel-learning/">Deep Kernel Learning with Lux</a></li><li><a class="tocitem" href="../examples/3-parametric-heteroscedastic/">Parametric Heteroscedastic Model</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Concrete Features</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Concrete Features</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/main/docs/src/concrete_features.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Features"><a class="docs-heading-anchor" href="#Features">Features</a><a id="Features-1"></a><a class="docs-heading-anchor-permalink" href="#Features" title="Permalink"></a></h1><h3 id="Setup"><a class="docs-heading-anchor" href="#Setup">Setup</a><a id="Setup-1"></a><a class="docs-heading-anchor-permalink" href="#Setup" title="Permalink"></a></h3><pre><code class="language-julia hljs">using AbstractGPs, Random
rng = MersenneTwister(0)

# Construct a zero-mean Gaussian process with a matern-3/2 kernel.
f = GP(Matern32Kernel())

# Specify some input and target locations.
x = randn(rng, 10)
y = randn(rng, 10)</code></pre><h2 id="Finite-dimensional-projection"><a class="docs-heading-anchor" href="#Finite-dimensional-projection">Finite dimensional projection</a><a id="Finite-dimensional-projection-1"></a><a class="docs-heading-anchor-permalink" href="#Finite-dimensional-projection" title="Permalink"></a></h2><p>Look at the finite-dimensional projection of <code>f</code> at <code>x</code>, under zero-mean observation noise with variance <code>0.1</code>.</p><pre><code class="language-julia hljs">fx = f(x, 0.1)</code></pre><h2 id="Sample-from-GP-from-the-prior-at-x-under-noise."><a class="docs-heading-anchor" href="#Sample-from-GP-from-the-prior-at-x-under-noise.">Sample from GP from the prior at <code>x</code> under noise.</a><a id="Sample-from-GP-from-the-prior-at-x-under-noise.-1"></a><a class="docs-heading-anchor-permalink" href="#Sample-from-GP-from-the-prior-at-x-under-noise." title="Permalink"></a></h2><pre><code class="language-julia hljs">y_sampled = rand(rng, fx)</code></pre><h2 id="Compute-the-log-marginal-probability-of-y."><a class="docs-heading-anchor" href="#Compute-the-log-marginal-probability-of-y.">Compute the log marginal probability of <code>y</code>.</a><a id="Compute-the-log-marginal-probability-of-y.-1"></a><a class="docs-heading-anchor-permalink" href="#Compute-the-log-marginal-probability-of-y." title="Permalink"></a></h2><pre><code class="language-julia hljs">logpdf(fx, y)</code></pre><h2 id="Construct-the-posterior-process-implied-by-conditioning-f-at-x-on-y."><a class="docs-heading-anchor" href="#Construct-the-posterior-process-implied-by-conditioning-f-at-x-on-y.">Construct the posterior process implied by conditioning <code>f</code> at <code>x</code> on <code>y</code>.</a><a id="Construct-the-posterior-process-implied-by-conditioning-f-at-x-on-y.-1"></a><a class="docs-heading-anchor-permalink" href="#Construct-the-posterior-process-implied-by-conditioning-f-at-x-on-y." title="Permalink"></a></h2><pre><code class="language-julia hljs">f_posterior = posterior(fx, y)</code></pre><h2 id="A-posterior-process-follows-the-AbstractGP-interface,-so-the-same-functions-which-work-on-the-posterior-as-on-the-prior."><a class="docs-heading-anchor" href="#A-posterior-process-follows-the-AbstractGP-interface,-so-the-same-functions-which-work-on-the-posterior-as-on-the-prior.">A posterior process follows the <code>AbstractGP</code> interface, so the same functions which work on the posterior as on the prior.</a><a id="A-posterior-process-follows-the-AbstractGP-interface,-so-the-same-functions-which-work-on-the-posterior-as-on-the-prior.-1"></a><a class="docs-heading-anchor-permalink" href="#A-posterior-process-follows-the-AbstractGP-interface,-so-the-same-functions-which-work-on-the-posterior-as-on-the-prior." title="Permalink"></a></h2><pre><code class="language-julia hljs">rand(rng, f_posterior(x))
logpdf(f_posterior(x), y)</code></pre><h2 id="Compute-the-VFE-approximation-to-the-log-marginal-probability-of-y."><a class="docs-heading-anchor" href="#Compute-the-VFE-approximation-to-the-log-marginal-probability-of-y.">Compute the VFE approximation to the log marginal probability of <code>y</code>.</a><a id="Compute-the-VFE-approximation-to-the-log-marginal-probability-of-y.-1"></a><a class="docs-heading-anchor-permalink" href="#Compute-the-VFE-approximation-to-the-log-marginal-probability-of-y." title="Permalink"></a></h2><p>Here, z is a set of pseudo-points.</p><pre><code class="language-julia hljs">z = randn(rng, 4)</code></pre><h3 id="Evidence-Lower-BOund-(ELBO)"><a class="docs-heading-anchor" href="#Evidence-Lower-BOund-(ELBO)">Evidence Lower BOund (ELBO)</a><a id="Evidence-Lower-BOund-(ELBO)-1"></a><a class="docs-heading-anchor-permalink" href="#Evidence-Lower-BOund-(ELBO)" title="Permalink"></a></h3><p>We provide a ready implentation of elbo w.r.t to the pseudo points. We can perform Variational Inference on pseudo-points by maximizing the ELBO term w.r.t pseudo-points <code>z</code> and any kernel parameters. For more information, see <a href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/tree/master/examples">examples</a>.</p><pre><code class="language-julia hljs">elbo(VFE(f(z)), fx, y)</code></pre><h3 id="Construct-the-approximate-posterior-process-implied-by-the-VFE-approximation."><a class="docs-heading-anchor" href="#Construct-the-approximate-posterior-process-implied-by-the-VFE-approximation.">Construct the approximate posterior process implied by the VFE approximation.</a><a id="Construct-the-approximate-posterior-process-implied-by-the-VFE-approximation.-1"></a><a class="docs-heading-anchor-permalink" href="#Construct-the-approximate-posterior-process-implied-by-the-VFE-approximation." title="Permalink"></a></h3><p>The optimal pseudo-points obtained above can be used to create a approximate/sparse posterior. This can be used like a regular posterior in many cases.</p><pre><code class="language-julia hljs">f_approx_posterior = posterior(VFE(f(z)), fx, y)</code></pre><h3 id="An-approximate-posterior-process-is-yet-another-AbstractGP,-so-you-can-do-things-with-it-like"><a class="docs-heading-anchor" href="#An-approximate-posterior-process-is-yet-another-AbstractGP,-so-you-can-do-things-with-it-like">An approximate posterior process is yet another <code>AbstractGP</code>, so you can do things with it like</a><a id="An-approximate-posterior-process-is-yet-another-AbstractGP,-so-you-can-do-things-with-it-like-1"></a><a class="docs-heading-anchor-permalink" href="#An-approximate-posterior-process-is-yet-another-AbstractGP,-so-you-can-do-things-with-it-like" title="Permalink"></a></h3><pre><code class="language-julia hljs">marginals(f_approx_posterior(x))</code></pre><h2 id="Sequential-Conditioning"><a class="docs-heading-anchor" href="#Sequential-Conditioning">Sequential Conditioning</a><a id="Sequential-Conditioning-1"></a><a class="docs-heading-anchor-permalink" href="#Sequential-Conditioning" title="Permalink"></a></h2><p>Sequential conditioning allows you to compute your posterior in an online fashion. We do this in an efficient manner by updating the cholesky factorisation of the covariance matrix and avoiding recomputing it from original covariance matrix.</p><pre><code class="language-julia hljs"># Define GP prior
f = GP(SqExponentialKernel())</code></pre><h3 id="Exact-Posterior"><a class="docs-heading-anchor" href="#Exact-Posterior">Exact Posterior</a><a id="Exact-Posterior-1"></a><a class="docs-heading-anchor-permalink" href="#Exact-Posterior" title="Permalink"></a></h3><p>Generate posterior with the first batch of data by conditioning the prior on them:</p><pre><code class="language-julia hljs">p_fx = posterior(f(x[1:3], 0.1), y[1:3])</code></pre><p>Generate posterior with the second batch of data, considering the previous posterior <code>p_fx</code> as the prior:</p><pre><code class="language-julia hljs">p_p_fx = posterior(p_fx(x[4:10], 0.1), y[4:10])</code></pre><h3 id="Approximate-Posterior"><a class="docs-heading-anchor" href="#Approximate-Posterior">Approximate Posterior</a><a id="Approximate-Posterior-1"></a><a class="docs-heading-anchor-permalink" href="#Approximate-Posterior" title="Permalink"></a></h3><h4 id="Adding-observations-in-a-sequential-fashion"><a class="docs-heading-anchor" href="#Adding-observations-in-a-sequential-fashion">Adding observations in a sequential fashion</a><a id="Adding-observations-in-a-sequential-fashion-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-observations-in-a-sequential-fashion" title="Permalink"></a></h4><pre><code class="language-julia hljs">Z1 = rand(rng, 4)
Z2 = rand(rng, 3)
Z = vcat(Z1, Z2)
p_fx1 = posterior(VFE(f(Z)), f(x[1:7], 0.1), y[1:7])
u_p_fx1 = update_posterior(p_fx1, f(x[8:10], 0.1), y[8:10])</code></pre><h4 id="Adding-pseudo-points-in-a-sequential-fashion"><a class="docs-heading-anchor" href="#Adding-pseudo-points-in-a-sequential-fashion">Adding pseudo-points in a sequential fashion</a><a id="Adding-pseudo-points-in-a-sequential-fashion-1"></a><a class="docs-heading-anchor-permalink" href="#Adding-pseudo-points-in-a-sequential-fashion" title="Permalink"></a></h4><pre><code class="language-julia hljs">p_fx2 = posterior(VFE(f(Z1)), f(x, 0.1), y)
u_p_fx2 = update_posterior(p_fx2, f(Z2))</code></pre><h2 id="Plotting"><a class="docs-heading-anchor" href="#Plotting">Plotting</a><a id="Plotting-1"></a><a class="docs-heading-anchor-permalink" href="#Plotting" title="Permalink"></a></h2><h3 id="Plots.jl"><a class="docs-heading-anchor" href="#Plots.jl">Plots.jl</a><a id="Plots.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Plots.jl" title="Permalink"></a></h3><p>We provide functions for plotting samples and predictions of Gaussian processes with <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a>. You can see some examples in the <a href="@ref">One-dimensional regression</a> tutorial.</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RecipesBase.plot-Tuple{AbstractVector, AbstractGPs.FiniteGP}" href="#RecipesBase.plot-Tuple{AbstractVector, AbstractGPs.FiniteGP}"><code>RecipesBase.plot</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">plot(x::AbstractVector, f::FiniteGP; ribbon_scale=1, kwargs...)
plot!([plot, ]x::AbstractVector, f::FiniteGP; ribbon_scale=1, kwargs...)</code></pre><p>Plot the predictive mean for the projection <code>f</code> of a Gaussian process and a ribbon of <code>ribbon_scale</code> standard deviations around it versus <code>x</code>.</p><div class="admonition is-info" id="Note-b7760df6f6bc2212"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-b7760df6f6bc2212" title="Permalink"></a></header><div class="admonition-body"><p>Make sure to load <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a> before you use this function.</p></div></div><p><strong>Examples</strong></p><p>Plot the mean and a ribbon of 3 standard deviations:</p><pre><code class="language-julia hljs">using Plots

gp = GP(SqExponentialKernel())
plot(gp(rand(5)); ribbon_scale=3)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/ef3edc2d49a0a1656660bef1aaaa9653e982f8d6/src/util/plotting.jl#L18-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RecipesBase.plot-Tuple{AbstractGPs.FiniteGP}" href="#RecipesBase.plot-Tuple{AbstractGPs.FiniteGP}"><code>RecipesBase.plot</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">plot(f::FiniteGP; kwargs...)
plot!([plot, ]f::FiniteGP; kwargs...)</code></pre><p>Plot the predictive mean and a ribbon around it for the projection <code>f</code> of a Gaussian process versus <code>f.x</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/ef3edc2d49a0a1656660bef1aaaa9653e982f8d6/src/util/plotting.jl#L48-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="RecipesBase.plot-Tuple{AbstractVector, AbstractGPs.AbstractGP}" href="#RecipesBase.plot-Tuple{AbstractVector, AbstractGPs.AbstractGP}"><code>RecipesBase.plot</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">plot(x::AbstractVector, gp::AbstractGP; kwargs...)
plot!([plot, ]x::AbstractVector, gp::AbstractGP; kwargs...)</code></pre><p>Plot the predictive mean and a ribbon around it for the projection <code>gp(x)</code> of the Gaussian process <code>gp</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/ef3edc2d49a0a1656660bef1aaaa9653e982f8d6/src/util/plotting.jl#L61-L67">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AbstractGPs.sampleplot" href="#AbstractGPs.sampleplot"><code>AbstractGPs.sampleplot</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sampleplot([x::AbstractVector=f.x, ]f::FiniteGP; samples=1, kwargs...)</code></pre><p>Plot samples from the projection <code>f</code> of a Gaussian process versus <code>x</code>.</p><div class="admonition is-info" id="Note-b7760df6f6bc2212"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-b7760df6f6bc2212" title="Permalink"></a></header><div class="admonition-body"><p>Make sure to load <a href="https://github.com/JuliaPlots/Plots.jl">Plots.jl</a> before you use this function.</p></div></div><p>When plotting multiple samples, these are treated as a <em>single</em> series (i.e., only a single entry will be added to the legend when providing a <code>label</code>).</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">using Plots

gp = GP(SqExponentialKernel())
sampleplot(gp(rand(5)); samples=10, linealpha=1.0)</code></pre><p>The given example plots 10 samples from the projection of the GP <code>gp</code>. The <code>linealpha</code> is modified from default of 0.35 to 1.</p><hr/><pre><code class="nohighlight hljs">sampleplot(x::AbstractVector, gp::AbstractGP; samples=1, kwargs...)</code></pre><p>Plot samples from the finite projection <code>gp(x, 1e-9)</code> versus <code>x</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGaussianProcesses/AbstractGPs.jl/blob/ef3edc2d49a0a1656660bef1aaaa9653e982f8d6/src/util/plotting.jl#L76-L103">source</a></section></article><h3 id="Makie.jl"><a class="docs-heading-anchor" href="#Makie.jl">Makie.jl</a><a id="Makie.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Makie.jl" title="Permalink"></a></h3><p>You can use the Julia package <a href="https://github.com/JuliaGaussianProcesses/AbstractGPsMakie.jl">AbstractGPsMakie.jl</a> to plot Gaussian processes with <a href="https://github.com/JuliaPlots/Makie.jl">Makie.jl</a>.</p><p><video src="https://juliagaussianprocesses.github.io/AbstractGPsMakie.jl/stable/posterior_animation.mp4" controls="true" title="posterior animation"><a href="https://juliagaussianprocesses.github.io/AbstractGPsMakie.jl/stable/posterior_animation.mp4">posterior animation</a></video></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/">« The Main APIs</a><a class="docs-footer-nextpage" href="../examples/0-intro-1d/">Intro to AbstractGPs: one-dimensional regression »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Friday 29 August 2025 14:46">Friday 29 August 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
